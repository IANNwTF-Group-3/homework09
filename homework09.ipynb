{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "-iT87FG8uF-9",
    "outputId": "2b5dc0b6-471d-4af8-c166-f09b6715d32b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "# disable compiler warnings\n",
    "import os\n",
    "\n",
    "# imports \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from typing import List\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'  # FATAL\n",
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import urllib\n",
    "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
    "print(categories[:10])\n",
    "category = 'candle'"
   ],
   "metadata": {
    "id": "uWx8FGGXuQNv",
    "outputId": "f4250a6c-96ef-4569-ef36-8ee830cf7c0c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'aircraft carrier', b'airplane', b'alarm clock', b'ambulance', b'angel', b'animal migration', b'ant', b'anvil', b'apple', b'arm']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Creates a folder to download the original drawings into.\n",
    "# We chose to use the numpy format : 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
    "\n",
    "if not os.path.isdir('npy_files'):\n",
    "    os.mkdir('npy_files')\n",
    "    \n",
    "url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
    "urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
    "\n",
    "images = np.load(f'npy_files/{category}.npy')\n",
    "print(f'{len(images)} images to train on')\n",
    "\n",
    "# You can limit the amount of images you use for training by setting :\n",
    "train_images = images[:10000]\n",
    "# You should also define a samller subset of the images for testing..\n",
    "val_images = images[10000:20000]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensors(train_images)\n",
    "val_ds = tf.data.Dataset.from_tensors(val_images)"
   ],
   "metadata": {
    "id": "vGLVztdbuclX",
    "outputId": "574b8268-b3aa-4dd9-c8e3-05c702bce666",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "141545 images to train on\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_data(dataset, batch_size):\n",
    "  dataset = dataset.map(lambda img: tf.reshape(img, [28, 28]))\n",
    "\n",
    "  dataset = dataset.map(lambda img: tf.cast(img, tf.float32))\n",
    "  \n",
    "  dataset = dataset.map(lambda img: (img/128.)-1.)\n",
    "\n",
    "  dataset = dataset.cache()\n",
    "  dataset = dataset.shuffle(4096)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "id": "LdPhNVS3wNWm"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    self.layers = [\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    "\n",
    "  def call(self, x, training=False):\n",
    "    for layer in self.my_layers:\n",
    "      x = layer(x)\n",
    "    return x"
   ],
   "metadata": {
    "id": "8v-dX8DoxeZj"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Generator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    self.layers = [\n",
    "        tf.keras.layers.Reshape((14, 14)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(1, kernel_size=2, padding='same')\n",
    "    ]\n",
    "\n",
    "  def call(self, x, training=False):\n",
    "    for layer in self.my_layers:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(self, data):\n",
    "      img, label = data\n",
    "      \n",
    "      # compute output and loss, train the variables\n",
    "      with tf.GradientTape() as tape:\n",
    "          output = self(img, training=True)\n",
    "          loss = self.loss_function(label, output)\n",
    "          \n",
    "      # update trainable variables\n",
    "      gradients = tape.gradient(loss, self.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "      # update metrics\n",
    "      self.metrics_list[1][0].update_state(tf.argmax(output, axis=1), tf.argmax(label, axis=1))\n",
    "      self.metrics_list[1][1].update_state(loss)\n",
    "      self.metrics_list[1][2].update_state(self.compute_frobenius())\n",
    "      \n",
    "      # return a dict with metric information\n",
    "      return {m.name : m.result() for m in self.metrics_list[1]}"
   ],
   "metadata": {
    "id": "mFuk1fnyyvPg"
   },
   "execution_count": 11,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
